## Lucky DDPM 实验指导手册

### 田野采集

![田野采集](./数据集收集记录/田野采集.jpg)

### 书签压扁

![书签压扁](./数据集收集记录/书签压扁.jpg)

### 拍摄照片

总共挑选了200片形状各异的三叶草，照了17张照片，放在raw文件夹。

前面的16张照片中，一次性拍摄12片三叶草，最后一张照片，拍摄8片三叶草。最后一张照片当中还混入了一个四叶草。

这一步要注意，使用黑色背景，方便之后把背景涂成全黑。

![书签压扁](./raw/01.jpg)

### 实例提取

通过open cv把一张图当中的12片三叶草提取出来，然后把背景涂黑。原来的图像是大约4000×4000像素的，提取之后的像素固定为128×128方便训练（如果想要换尺寸，改一处参数即可）。

原本有17张大图，提取之后有200张小图，200张小图放在data文件夹。

```shell
python extract_instances.py
```

![image-20260220193939287](./assets/image-20260220193939287.png)

### 数据增强

因为200张图对于训练ddpm模型还是少了，所以对200张小图进行数据增强，通过旋转、翻转和缩放，变成2000张图，放入dataset文件夹。

从图中可以看到意外混入的一片四叶草进行了数据增强，连续生成了10张，由于训练的时候是打乱的，所以不影响。

```shell
python augment.py
```

![image-20260220193645014](./assets/image-20260220193645014.png)

### 租服务器

![image-20260205122131516](./assets/image-20260205122131516-1771577085464-10.png)

![image-20260205123656983](./assets/image-20260205123656983.png)

![image-20260205123915702](./assets/image-20260205123915702.png)

### 远程登录服务器

![image-20260205125811433](./assets/image-20260205125811433-1771577085465-13.png)

![image-20260205125629538](./assets/image-20260205125629538.png)

![image-20260205124419443](./assets/image-20260205124419443-1771577085465-16.png)

![image-20260205124753438](./assets/image-20260205124753438-1771577085465-17.png)

### 下载github仓库

先给联网加个速[只在当前端口生效] [服务器不方便配置代理]

```shell
source /etc/network_turbo
```

下载仓库和数据集

```shell
git clone https://github.com/HaiPenglai/Lucky-DDPM
```

### 安装OpenCV

因为没有预装OpenCV，所以需要装一下。否则报错：` No module named 'cv2'`。除此之外，还需要安装`diffusers`（`hugging face`的，类似于`transformers`）。

```shell
pip install opencv-python-headless diffusers accelerate tqdm matplotlib pillow
```

![image-20260220165411519](./assets/image-20260220165411519.png)

这里可能会有一个提示，就是建议用虚拟环境，而不是在base环境。但是因为在服务器上用完就关了，所以用base环境也无伤大雅，如果自己的环境的话，小心把环境搞乱了，还是要开一个虚拟环境。

### 原地处理数据

因为实例提取和数据增强这两个步骤，几秒钟就能做完，直接从大图原地处理更好。

```shell
python ./extract_instances.py
python ./augment.py
```

### 开始训练

```shell
python ./train.py
```



### 训练监控

每训练10轮，也就是模型把2000张图片走10遍，就会去生成几个样图。每10轮生成的效果如下：



## 附录

### OpenCV幸运草分割遇到的7大坑

- **坑一：全图误判（全局识别失败）**
  - **问题描述**：脚本运行后，只生成了一张巨大的图，或者将整个黑色背景布识别为一个“超级四叶草”。
  - **原因**：仅靠亮度（灰度）阈值分割太脆弱，背景布的微弱纹理或反光会被误认为目标，且缺少物体面积的上限限制。
  - **方案**：**HSV颜色锁死 + 动态面积比例**。利用 `inRange` 只看绿色通道，并设置物体面积不得超过全图 20% 的硬性过滤。

- **坑二：非均匀拉伸（几何畸变）**
  - **问题描述**：切出来的四叶草看起来“变瘦”或“变扁”了。
  - **原因**：靠近边缘的草在切割时，正方形区域被图片边界截断，导致长宽比失调，再强行缩放到 512x512 时产生拉伸。
  - **方案**：**黑色正方形画布（Padding）**。先按原始比例切出草，再将其粘贴到手动构建的纯黑正方形画布中心。

- **坑三：背景噪声与框线感（特征污染）**
  - **问题描述**：生成的图片中隐约能看见垫子上的白线、灰尘，或者草周围有一圈暗淡的色块（物理黑与数字黑的边界）。
  - **原因**：相机捕捉的“黑色背景”并非绝对的零（Digital Zero），而是带有纹理和噪点的物理色块，AI会学习这些非结构化噪声。
  - **方案**：**背景掩码清零（Background Nulling）**。利用掩码（Mask）对非绿色区域进行位运算，强制将所有背景像素点抹除为绝对的 `(0, 0, 0)`。

- **坑四：中心阴影残留（分割伪影）**
  - **问题描述**：叶片汇聚的中心处经常有难以去除的灰色色块，破坏了草的拓扑美感。
  - **原因**：**单掩码悖论**。为了把散开的叶子连起来，使用了过大的卷积核进行闭运算，结果把中间的阴影也“粘”成了草。
  - **方案**：**双掩码策略（Dual-Mask）**。使用大核掩码（50x50）负责“定位”物体边界，使用小核/原色掩码负责“抠图”细节，兼顾完整性与精细度。

- **坑五：散叶草“分家”（拓扑断裂）**
  - **问题描述**：叶片张得比较开的四叶草（如5号草）被切成了 3 张独立的碎叶图，无法作为一个整体。
  - **原因**：连通域检测时卷积核太小，未能跨越叶片间的缝隙，导致一个四叶草被判定为多个独立轮廓。
  - **方案**：**超大核膨胀粘合**。在定位阶段执行强力闭运算（Morphology Close），强行将 50 像素内的“孤岛”连成大陆。

- **坑六：叶片内部穿孔（细节损毁）**
  - **问题描述**：处理后的叶片中间出现莫名其妙的黑色小点，像被虫蛀过。
  - **原因**：叶脉深色区域或叶片上的反光被 HSV 过滤误杀，加之去噪用的开运算太重，把内部特征当成背景剔除了。
  - **方案**：**暴力孔洞填充（Hole Filling）**。在获得叶片外轮廓后，使用 `cv2.drawContours` 的 `-1` 填充参数，直接将轮廓内部全部涂色，从物理上消除所有内部“穿孔”。

- **坑七：黄色叶片被掩码**
  - **问题描述**：处理后的叶片中，黄色区域被错误地掩码了，导致叶面缺叶。
  - **方案**：用取色笔获取了黄色区域的颜色值，据此调整，`mask_raw = cv2.inRange(hsv, np.array([25, 70, 30]), np.array([90, 255, 255]))`之后改善了。

